{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Rangkuman Chapter 1: The Machine Learning Landscape\n",
        "\n",
        "## Disusun berdasarkan buku \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\"\n",
        "\n",
        "Notebook ini berisi rangkuman lengkap Chapter 1 dengan implementasi Python untuk testing dan validating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Apa itu Machine Learning?\n",
        "\n",
        "Machine Learning adalah ilmu (dan seni) memprogram komputer agar dapat belajar dari data.\n",
        "\n",
        "**Definisi formal (Tom Mitchell, 1997):**\n",
        "\n",
        "> Sebuah program komputer dikatakan belajar dari pengalaman E dengan respect terhadap tugas T dan ukuran performa P, jika performanya pada T, yang diukur oleh P, meningkat dengan pengalaman E.\n",
        "\n",
        "**Contoh Spam Filter:**\n",
        "- **Task (T)**: Menandai email spam\n",
        "- **Experience (E)**: Training data (email yang sudah dilabeli)\n",
        "- **Performance (P)**: Accuracy (rasio email yang diklasifikasi dengan benar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Mengapa Menggunakan Machine Learning?\n",
        "\n",
        "ML sangat berguna untuk:\n",
        "1. **Problem yang memerlukan banyak fine-tuning atau rules yang panjang**\n",
        "2. **Problem kompleks yang tidak ada solusi tradisional yang baik**\n",
        "3. **Lingkungan yang berubah-ubah**: ML system dapat beradaptasi dengan data baru\n",
        "4. **Mendapatkan insight dari data dalam jumlah besar**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Tipe-Tipe Machine Learning Systems\n",
        "\n",
        "### 3.1 Supervised vs Unsupervised Learning\n",
        "\n",
        "#### Supervised Learning\n",
        "Training set sudah memiliki label/solusi yang diinginkan.\n",
        "\n",
        "**Algoritma utama:**\n",
        "- k-Nearest Neighbors\n",
        "- Linear Regression\n",
        "- Logistic Regression\n",
        "- Support Vector Machines (SVMs)\n",
        "- Decision Trees and Random Forests\n",
        "- Neural networks\n",
        "\n",
        "#### Unsupervised Learning\n",
        "Training data tidak memiliki label.\n",
        "\n",
        "**Algoritma utama:**\n",
        "- **Clustering**: K-Means, DBSCAN, HCA\n",
        "- **Anomaly detection**: One-class SVM, Isolation Forest\n",
        "- **Dimensionality reduction**: PCA, Kernel PCA, LLE, t-SNE\n",
        "\n",
        "### 3.2 Batch vs Online Learning\n",
        "\n",
        "- **Batch Learning**: Model dilatih dengan semua data sekaligus (offline)\n",
        "- **Online Learning**: Model dilatih secara incremental dengan data yang datang secara sequential\n",
        "\n",
        "### 3.3 Instance-Based vs Model-Based Learning\n",
        "\n",
        "- **Instance-Based**: Belajar dengan menghafal contoh, lalu generalisasi dengan similarity measure\n",
        "- **Model-Based**: Membangun model dari contoh, lalu gunakan model untuk prediksi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Main Challenges of Machine Learning\n",
        "\n",
        "### 4.1 Bad Data\n",
        "1. **Insufficient Quantity of Training Data**: Butuh ribuan hingga jutaan contoh\n",
        "2. **Nonrepresentative Training Data**: Data training harus representatif terhadap data baru\n",
        "3. **Poor-Quality Data**: Error, outlier, noise\n",
        "4. **Irrelevant Features**: Feature engineering penting untuk kesuksesan ML\n",
        "\n",
        "### 4.2 Bad Algorithm\n",
        "1. **Overfitting**: Model terlalu kompleks, performa baik di training tapi buruk di data baru\n",
        "   - Solusi: Simplify model, lebih banyak data, reduce noise, regularization\n",
        "2. **Underfitting**: Model terlalu sederhana\n",
        "   - Solusi: Model lebih powerful, feature engineering, reduce constraints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Testing and Validating\n",
        "\n",
        "Cara untuk mengetahui seberapa baik model generalisasi adalah dengan mengujinya pada data baru.\n",
        "\n",
        "### 5.1 Split Data\n",
        "- **Training Set (80%)**: Untuk training model\n",
        "- **Test Set (20%)**: Untuk evaluasi generalization error\n",
        "\n",
        "### 5.2 Hyperparameter Tuning and Model Selection\n",
        "Gunakan **validation set** atau **cross-validation**:\n",
        "- **Holdout Validation**: Pisahkan sebagian training set untuk validation\n",
        "- **Cross-Validation**: Gunakan beberapa validation sets kecil, average hasilnya\n",
        "\n",
        "### 5.3 Dataset Split\n",
        "- **Training Set**: Untuk training model\n",
        "- **Validation Set**: Untuk hyperparameter tuning dan model selection\n",
        "- **Test Set**: Untuk evaluasi final (jangan disentuh sampai akhir!)\n",
        "- **Train-dev Set**: Untuk detect data mismatch (optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Contoh Implementasi: Model-Based Learning\n",
        "\n",
        "### Studi Kasus: Apakah uang membuat orang bahagia?\n",
        "\n",
        "Kita akan membuat model linear untuk memprediksi life satisfaction berdasarkan GDP per capita."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create sample data (GDP per capita vs Life Satisfaction)\n",
        "# Data berdasarkan contoh dari buku\n",
        "\n",
        "country_stats = pd.DataFrame({\n",
        "    'Country': ['Hungary', 'Korea', 'France', 'Australia', 'United States'],\n",
        "    'GDP per capita': [12240, 27195, 37675, 50962, 55805],\n",
        "    'Life satisfaction': [4.9, 5.8, 6.5, 7.3, 7.2]\n",
        "})\n",
        "\n",
        "print(\"\\nCountry Statistics:\")\n",
        "print(country_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualisasi data\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(country_stats['GDP per capita'], country_stats['Life satisfaction'], s=100)\n",
        "plt.xlabel('GDP per capita (USD)', fontsize=12)\n",
        "plt.ylabel('Life satisfaction', fontsize=12)\n",
        "plt.title('Does Money Make People Happy?', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Add country labels\n",
        "for idx, row in country_stats.iterrows():\n",
        "    plt.annotate(row['Country'], \n",
        "                 (row['GDP per capita'], row['Life satisfaction']),\n",
        "                 xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Dari plot terlihat ada trend linear positif antara GDP per capita dan Life satisfaction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 1: Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for training\n",
        "X = country_stats[['GDP per capita']].values  # Features (2D array)\n",
        "y = country_stats['Life satisfaction'].values  # Target\n",
        "\n",
        "print(\"Feature shape (X):\", X.shape)\n",
        "print(\"Target shape (y):\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Linear Regression model\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X, y)\n",
        "\n",
        "# Display model parameters\n",
        "print(\"\\n=== Linear Regression Model ===\")\n",
        "print(f\"Intercept (θ0): {lin_reg.intercept_:.2f}\")\n",
        "print(f\"Coefficient (θ1): {lin_reg.coef_[0]:.2e}\")\n",
        "print(f\"\\nModel equation: Life_satisfaction = {lin_reg.intercept_:.2f} + {lin_reg.coef_[0]:.2e} × GDP_per_capita\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make prediction for Cyprus\n",
        "cyprus_gdp = [[22587]]  # Cyprus's GDP per capita\n",
        "cyprus_prediction = lin_reg.predict(cyprus_gdp)\n",
        "\n",
        "print(f\"\\nPrediction for Cyprus (GDP per capita = ${cyprus_gdp[0][0]:,}):\")\n",
        "print(f\"Predicted Life Satisfaction: {cyprus_prediction[0]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the model\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot data points\n",
        "plt.scatter(X, y, s=100, label='Training data', color='blue', zorder=5)\n",
        "\n",
        "# Plot regression line\n",
        "X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
        "y_plot = lin_reg.predict(X_plot)\n",
        "plt.plot(X_plot, y_plot, 'r-', linewidth=2, label='Linear Regression', zorder=4)\n",
        "\n",
        "# Plot Cyprus prediction\n",
        "plt.scatter(cyprus_gdp, cyprus_prediction, s=200, marker='*', \n",
        "           color='green', label='Cyprus (prediction)', zorder=6, edgecolors='black', linewidth=1.5)\n",
        "\n",
        "plt.xlabel('GDP per capita (USD)', fontsize=12)\n",
        "plt.ylabel('Life satisfaction', fontsize=12)\n",
        "plt.title('Linear Regression Model', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model 2: k-Nearest Neighbors Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train k-NN model\n",
        "knn_reg = KNeighborsRegressor(n_neighbors=3)\n",
        "knn_reg.fit(X, y)\n",
        "\n",
        "# Make prediction for Cyprus\n",
        "cyprus_prediction_knn = knn_reg.predict(cyprus_gdp)\n",
        "\n",
        "print(\"\\n=== k-Nearest Neighbors (k=3) Model ===\")\n",
        "print(f\"Prediction for Cyprus: {cyprus_prediction_knn[0]:.2f}\")\n",
        "\n",
        "# Compare with Linear Regression\n",
        "print(f\"\\nComparison:\")\n",
        "print(f\"Linear Regression: {cyprus_prediction[0]:.2f}\")\n",
        "print(f\"k-NN Regression (k=3): {cyprus_prediction_knn[0]:.2f}\")\n",
        "print(f\"Difference: {abs(cyprus_prediction[0] - cyprus_prediction_knn[0]):.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Testing and Validating: Implementasi Praktis\n",
        "\n",
        "Sekarang kita akan implementasikan konsep testing dan validating dengan dataset yang lebih besar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create larger synthetic dataset\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate 100 data points\n",
        "n_samples = 100\n",
        "X_full = np.random.uniform(10000, 60000, n_samples).reshape(-1, 1)\n",
        "\n",
        "# True relationship: life_satisfaction = 4.5 + 5e-5 * GDP + noise\n",
        "y_full = 4.5 + 5e-5 * X_full.ravel() + np.random.normal(0, 0.3, n_samples)\n",
        "\n",
        "# Create DataFrame\n",
        "full_data = pd.DataFrame({\n",
        "    'GDP per capita': X_full.ravel(),\n",
        "    'Life satisfaction': y_full\n",
        "})\n",
        "\n",
        "print(f\"Total dataset size: {len(full_data)} samples\")\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "print(full_data.head())\n",
        "print(f\"\\nDataset statistics:\")\n",
        "print(full_data.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data: 80% training, 20% testing\n",
        "X_full_data = full_data[['GDP per capita']].values\n",
        "y_full_data = full_data['Life satisfaction'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_full_data, y_full_data, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"=== Data Split ===\")\n",
        "print(f\"Training set size: {len(X_train)} samples ({len(X_train)/len(X_full_data)*100:.0f}%)\")\n",
        "print(f\"Test set size: {len(X_test)} samples ({len(X_test)/len(X_full_data)*100:.0f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Train model on training set\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n=== Model Performance ===\")\n",
        "print(\"\\nTraining Set:\")\n",
        "print(f\"  RMSE: {train_rmse:.4f}\")\n",
        "print(f\"  MAE:  {train_mae:.4f}\")\n",
        "print(f\"  R²:   {train_r2:.4f}\")\n",
        "\n",
        "print(\"\\nTest Set (Generalization Error):\")\n",
        "print(f\"  RMSE: {test_rmse:.4f}\")\n",
        "print(f\"  MAE:  {test_mae:.4f}\")\n",
        "print(f\"  R²:   {test_r2:.4f}\")\n",
        "\n",
        "# Check for overfitting\n",
        "print(\"\\n=== Overfitting Check ===\")\n",
        "if test_rmse > train_rmse * 1.2:\n",
        "    print(\"⚠️  Warning: Model might be overfitting!\")\n",
        "    print(f\"   Test RMSE is {(test_rmse/train_rmse - 1)*100:.1f}% higher than train RMSE\")\n",
        "else:\n",
        "    print(\"✓ Model generalizes well (no significant overfitting detected)\")\n",
        "    print(f\"  Test RMSE is only {(test_rmse/train_rmse - 1)*100:.1f}% higher than train RMSE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize predictions\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Training and Test data with model\n",
        "ax1.scatter(X_train, y_train, alpha=0.5, label='Training data', s=50)\n",
        "ax1.scatter(X_test, y_test, alpha=0.5, label='Test data', s=50, color='orange')\n",
        "\n",
        "X_plot = np.linspace(X_full_data.min(), X_full_data.max(), 100).reshape(-1, 1)\n",
        "y_plot = model.predict(X_plot)\n",
        "ax1.plot(X_plot, y_plot, 'r-', linewidth=2, label='Model')\n",
        "\n",
        "ax1.set_xlabel('GDP per capita (USD)', fontsize=11)\n",
        "ax1.set_ylabel('Life satisfaction', fontsize=11)\n",
        "ax1.set_title('Model Fit on Train/Test Data', fontsize=12, fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Predicted vs Actual\n",
        "ax2.scatter(y_test, y_test_pred, alpha=0.6, s=50)\n",
        "ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
        "         'r--', lw=2, label='Perfect prediction')\n",
        "ax2.set_xlabel('Actual Life Satisfaction', fontsize=11)\n",
        "ax2.set_ylabel('Predicted Life Satisfaction', fontsize=11)\n",
        "ax2.set_title('Predicted vs Actual (Test Set)', fontsize=12, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3 Cross-Validation\n",
        "\n",
        "Cross-validation memberikan estimasi performa yang lebih akurat dengan menggunakan multiple validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, cross_validate\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "cv_results = cross_validate(\n",
        "    model, X_train, y_train, \n",
        "    cv=5,\n",
        "    scoring=['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2'],\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "# Convert negative MSE to RMSE\n",
        "train_rmse_cv = np.sqrt(-cv_results['train_neg_mean_squared_error'])\n",
        "test_rmse_cv = np.sqrt(-cv_results['test_neg_mean_squared_error'])\n",
        "\n",
        "train_mae_cv = -cv_results['train_neg_mean_absolute_error']\n",
        "test_mae_cv = -cv_results['test_neg_mean_absolute_error']\n",
        "\n",
        "train_r2_cv = cv_results['train_r2']\n",
        "test_r2_cv = cv_results['test_r2']\n",
        "\n",
        "print(\"\\n=== 5-Fold Cross-Validation Results ===\")\n",
        "print(\"\\nRMSE per fold:\")\n",
        "for i, (train_score, test_score) in enumerate(zip(train_rmse_cv, test_rmse_cv), 1):\n",
        "    print(f\"  Fold {i}: Train={train_score:.4f}, Validation={test_score:.4f}\")\n",
        "\n",
        "print(\"\\nAverage Scores:\")\n",
        "print(f\"  Train RMSE: {train_rmse_cv.mean():.4f} (±{train_rmse_cv.std():.4f})\")\n",
        "print(f\"  Valid RMSE: {test_rmse_cv.mean():.4f} (±{test_rmse_cv.std():.4f})\")\n",
        "print(f\"  Train MAE:  {train_mae_cv.mean():.4f} (±{train_mae_cv.std():.4f})\")\n",
        "print(f\"  Valid MAE:  {test_mae_cv.mean():.4f} (±{test_mae_cv.std():.4f})\")\n",
        "print(f\"  Train R²:   {train_r2_cv.mean():.4f} (±{train_r2_cv.std():.4f})\")\n",
        "print(f\"  Valid R²:   {test_r2_cv.mean():.4f} (±{test_r2_cv.std():.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize cross-validation results\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "metrics = [\n",
        "    ('RMSE', train_rmse_cv, test_rmse_cv),\n",
        "    ('MAE', train_mae_cv, test_mae_cv),\n",
        "    ('R²', train_r2_cv, test_r2_cv)\n",
        "]\n",
        "\n",
        "for ax, (metric_name, train_scores, valid_scores) in zip(axes, metrics):\n",
        "    folds = np.arange(1, 6)\n",
        "    \n",
        "    ax.plot(folds, train_scores, 'o-', label='Train', linewidth=2, markersize=8)\n",
        "    ax.plot(folds, valid_scores, 's-', label='Validation', linewidth=2, markersize=8)\n",
        "    \n",
        "    ax.axhline(train_scores.mean(), color='blue', linestyle='--', alpha=0.5, linewidth=1)\n",
        "    ax.axhline(valid_scores.mean(), color='orange', linestyle='--', alpha=0.5, linewidth=1)\n",
        "    \n",
        "    ax.set_xlabel('Fold', fontsize=11)\n",
        "    ax.set_ylabel(metric_name, fontsize=11)\n",
        "    ax.set_title(f'{metric_name} across Folds', fontsize=12, fontweight='bold')\n",
        "    ax.set_xticks(folds)\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.4 Hyperparameter Tuning Example\n",
        "\n",
        "Demonstrasi tuning hyperparameter untuk k-NN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Try different values of k\n",
        "k_values = [1, 2, 3, 5, 7, 10, 15]\n",
        "train_scores = []\n",
        "valid_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsRegressor(n_neighbors=k)\n",
        "    \n",
        "    # Cross-validation\n",
        "    cv_results = cross_validate(\n",
        "        knn, X_train, y_train, \n",
        "        cv=5,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        return_train_score=True\n",
        "    )\n",
        "    \n",
        "    train_rmse = np.sqrt(-cv_results['train_neg_mean_squared_error'].mean())\n",
        "    valid_rmse = np.sqrt(-cv_results['test_neg_mean_squared_error'].mean())\n",
        "    \n",
        "    train_scores.append(train_rmse)\n",
        "    valid_scores.append(valid_rmse)\n",
        "    \n",
        "    print(f\"k={k:2d}: Train RMSE={train_rmse:.4f}, Valid RMSE={valid_rmse:.4f}\")\n",
        "\n",
        "# Find best k\n",
        "best_k_idx = np.argmin(valid_scores)\n",
        "best_k = k_values[best_k_idx]\n",
        "print(f\"\\n✓ Best k: {best_k} (Valid RMSE: {valid_scores[best_k_idx]:.4f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize hyperparameter tuning\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_values, train_scores, 'o-', label='Training RMSE', linewidth=2, markersize=8)\n",
        "plt.plot(k_values, valid_scores, 's-', label='Validation RMSE', linewidth=2, markersize=8)\n",
        "plt.axvline(best_k, color='green', linestyle='--', alpha=0.7, label=f'Best k={best_k}')\n",
        "plt.xlabel('k (number of neighbors)', fontsize=12)\n",
        "plt.ylabel('RMSE', fontsize=12)\n",
        "plt.title('Hyperparameter Tuning: k-NN', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nObservasi:\")\n",
        "print(\"- k terlalu kecil: model overfit (training error rendah, validation error tinggi)\")\n",
        "print(\"- k terlalu besar: model underfit (kedua error tinggi)\")\n",
        "print(f\"- k optimal: {best_k} (balance antara bias dan variance)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.5 Final Model Evaluation\n",
        "\n",
        "Setelah memilih model dan hyperparameter terbaik menggunakan validation set,\n",
        "kita evaluasi performa final pada test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final model with best hyperparameter on full training set\n",
        "final_model = KNeighborsRegressor(n_neighbors=best_k)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_test_pred_final = final_model.predict(X_test)\n",
        "\n",
        "final_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred_final))\n",
        "final_mae = mean_absolute_error(y_test, y_test_pred_final)\n",
        "final_r2 = r2_score(y_test, y_test_pred_final)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"FINAL MODEL EVALUATION ON TEST SET\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Model: k-NN Regression with k={best_k}\")\n",
        "print(f\"\\nTest Set Performance:\")\n",
        "print(f\"  RMSE: {final_rmse:.4f}\")\n",
        "print(f\"  MAE:  {final_mae:.4f}\")\n",
        "print(f\"  R²:   {final_r2:.4f}\")\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"✓ Model is ready for production!\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Demonstrasi Overfitting vs Underfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Create models with different complexities\n",
        "models = [\n",
        "    (\"Underfitting (degree=1)\", 1, 'blue'),\n",
        "    (\"Good fit (degree=2)\", 2, 'green'),\n",
        "    (\"Overfitting (degree=15)\", 15, 'red')\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
        "\n",
        "for ax, (title, degree, color) in zip(axes, models):\n",
        "    # Create and train polynomial model\n",
        "    poly_model = make_pipeline(\n",
        "        PolynomialFeatures(degree=degree),\n",
        "        LinearRegression()\n",
        "    )\n",
        "    poly_model.fit(X_train, y_train)\n",
        "    \n",
        "    # Calculate scores\n",
        "    train_score = poly_model.score(X_train, y_train)\n",
        "    test_score = poly_model.score(X_test, y_test)\n",
        "    \n",
        "    # Plot\n",
        "    ax.scatter(X_train, y_train, alpha=0.5, s=30, label='Train')\n",
        "    ax.scatter(X_test, y_test, alpha=0.5, s=30, color='orange', label='Test')\n",
        "    \n",
        "    X_plot = np.linspace(X_train.min(), X_train.max(), 200).reshape(-1, 1)\n",
        "    y_plot = poly_model.predict(X_plot)\n",
        "    ax.plot(X_plot, y_plot, color=color, linewidth=2, label='Model')\n",
        "    \n",
        "    ax.set_xlabel('GDP per capita', fontsize=10)\n",
        "    ax.set_ylabel('Life satisfaction', fontsize=10)\n",
        "    ax.set_title(f'{title}\\nTrain R²={train_score:.3f}, Test R²={test_score:.3f}', \n",
        "                fontsize=11, fontweight='bold')\n",
        "    ax.legend(fontsize=9)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Set y-axis limits for degree=15 to show overfitting better\n",
        "    if degree == 15:\n",
        "        ax.set_ylim([y_full_data.min() - 1, y_full_data.max() + 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPenjelasan:\")\n",
        "print(\"1. Underfitting (kiri): Model terlalu sederhana, performa buruk di train & test\")\n",
        "print(\"2. Good fit (tengah): Model pas, performa baik di train & test\")\n",
        "print(\"3. Overfitting (kanan): Model terlalu kompleks, performa sangat baik di train tapi buruk di test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary & Best Practices\n",
        "\n",
        "### Workflow Machine Learning Project:\n",
        "1. **Study the data**: Pahami data dan visualisasi\n",
        "2. **Select a model**: Pilih tipe model yang sesuai\n",
        "3. **Split data**: Train (80%) / Test (20%)\n",
        "4. **Train the model**: Fit model pada training data\n",
        "5. **Hyperparameter tuning**: Gunakan validation set atau cross-validation\n",
        "6. **Evaluate**: Test pada test set untuk estimasi generalization error\n",
        "7. **Deploy**: Jika performa memuaskan, deploy ke production\n",
        "\n",
        "### Important Points:\n",
        "- **Training Set**: Untuk melatih model\n",
        "- **Validation Set**: Untuk memilih model dan tune hyperparameter\n",
        "- **Test Set**: Untuk evaluasi final (JANGAN DISENTUH sampai akhir!)\n",
        "- **Cross-Validation**: Memberikan estimasi performa yang lebih reliable\n",
        "- **Overfitting**: Model terlalu kompleks → regularization, more data, simplify\n",
        "- **Underfitting**: Model terlalu sederhana → more complex model, feature engineering\n",
        "\n",
        "### Metrics untuk Evaluasi:\n",
        "- **RMSE** (Root Mean Squared Error): Penalti lebih besar untuk error besar\n",
        "- **MAE** (Mean Absolute Error): Lebih robust terhadap outliers\n",
        "- **R²** (Coefficient of Determination): Proporsi variance yang dijelaskan (0-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Exercises (dari buku)\n",
        "\n",
        "### Pertanyaan untuk Self-Assessment:\n",
        "\n",
        "1. Bagaimana Anda mendefinisikan Machine Learning?\n",
        "2. Sebutkan 4 tipe problem di mana ML sangat berguna\n",
        "3. Apa itu labeled training set?\n",
        "4. Apa dua supervised task yang paling umum?\n",
        "5. Sebutkan 4 unsupervised task yang umum\n",
        "6. Algoritma ML tipe apa yang akan Anda gunakan untuk robot berjalan di terrain yang tidak diketahui?\n",
        "7. Algoritma tipe apa untuk segmentasi customer?\n",
        "8. Apakah spam detection supervised atau unsupervised?\n",
        "9. Apa itu online learning system?\n",
        "10. Apa itu out-of-core learning?\n",
        "11. Algoritma tipe apa yang menggunakan similarity measure?\n",
        "12. Apa perbedaan model parameter vs hyperparameter?\n",
        "13. Apa yang dicari model-based learning algorithm?\n",
        "14. Sebutkan 4 main challenges dalam ML\n",
        "15. Jika model performa bagus di training tapi buruk di data baru, apa masalahnya?\n",
        "16. Apa itu test set dan mengapa dibutuhkan?\n",
        "17. Apa tujuan validation set?\n",
        "18. Apa itu train-dev set?\n",
        "19. Apa yang salah jika tune hyperparameter menggunakan test set?\n",
        "\n",
        "### Jawaban ada di Appendix A buku"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kesimpulan\n",
        "\n",
        "Chapter 1 memberikan fondasi penting untuk memahami Machine Learning:\n",
        "\n",
        "✓ **Konsep dasar ML**: Learning from data untuk improve performance\n",
        "\n",
        "✓ **Tipe-tipe ML**: Supervised, Unsupervised, Batch, Online, Instance-based, Model-based\n",
        "\n",
        "✓ **Main challenges**: Bad data (insufficient, nonrepresentative, poor quality, irrelevant features) dan bad algorithm (overfitting, underfitting)\n",
        "\n",
        "✓ **Testing & Validation**: Critical untuk mengukur generalization error dan memilih model terbaik\n",
        "\n",
        "✓ **Best practices**: Always split data, use cross-validation, tune hyperparameters properly, evaluate on test set only once\n",
        "\n",
        "---\n",
        "\n",
        "**Next Chapter**: End-to-end Machine Learning project dengan real dataset!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}